---
title: "Wahlen 2019: FB Ad Library"
author: "SRF Data, Timo Grossenbacher (timo.grossenbacher@srf.ch), Aline Metzler"
date: "August 2019"
output:
  html_document:
    code_folding: hide
    echo: TRUE
    warning: FALSE
    message: FALSE
    theme: simplex
    df_print: kable
    toc: yes
    toc_depth: 4
    toc_float: 
      collapsed: false
      smooth_scroll: false
subtitle: Täglich aktualisierte Auswertung
---


```{r, echo=FALSE}
# CONFIG
user_name <- "srfdata" # github user name
project_name <- "2019-08-fb-ad-library" # adapt to new repo name
package_date <- "2019-03-01" # date of the CRAN snapshot that
# the checkpoint package uses
R_version <- "3.5.3" # R-Version to use
options(Ncpus = 4) # use 4 cores for parallelized installation of packages
if (R_version != paste0(version$major, ".", version$minor)){
  stop("ERROR: specified R version does not match currently used.")
}
```

## Vorbemerkungen

In diesem Dokument werden einmal täglich alle Facebook-Werbeanzeigen ("Ads") Schweizer Parteien ausgewertet. Kontext: https://www.srf.ch/news/schweiz/wahlen-2019/wahlen-2019-der-facebook-wahlkampf-nimmt-fahrt-auf

**Zuletzt aktualisiert um `r Sys.time()` mit Daten, die zwischen 00:00 und 03:00 akquiriert wurden.**

**ACHTUNG**: *Die Daten, die aus der Ad Library zurückgegeben werden, sind aus verschiedensten Gründen lückenhaft und teils möglicherweise fehlerhaft (siehe dazu [diesen](https://disinfo.quaidorsay.fr/en/facebook-ads-library-assessment) und [diesen](https://adtransparency.mozilla.org/eu/log/) Bericht). Bei der Interpretation der untenstehenden Auswertungen ist deshalb Vorsicht geboten. Darüber hinaus wird jegliche Haftung für die nachfolgenden Angaben ausgeschlossen (siehe "Haftungsausschluss").*

SRF Data legt Wert darauf, dass die Datenvorprozessierung und -Analyse nachvollzogen und überprüft werden kann. SRF Data glaubt an das Prinzip offener Daten, aber auch offener und nachvollziehbarer Methoden. Zum anderen soll es Dritten ermöglicht werden, auf dieser Vorarbeit aufzubauen und damit weitere Auswertungen oder Applikationen zu generieren.  

Die Endprodukte des vorliegenden Scripts, neben der vorliegenden explorativen Analyse, sind:

* `output/ads.csv`: Die verschiedenen Zeitstände von Ads inkl. der Angaben, die im Frontend der Ad Library angezeigt werden, exkl. demographischer Angaben (Datenbeschreibung siehe unten).

**Für eine Beschreibung der Vorgehensweise siehe das Unterkapitel "Vorgehensweise".**

### R-Script & Daten

Die Vorprozessierung und Analyse wurde im Statistikprogramm R vorgenommen. Das zugrunde liegende Script sowie die prozessierten Daten können unter [diesem Link](https://srfdata.github.io/`r project_name`/rscript.zip) heruntergeladen werden. Durch Ausführen von `main.Rmd` kann der hier beschriebene Prozess nachvollzogen und der für den Artikel verwendete Datensatz generiert werden. Dabei werden Daten aus dem Ordner `input` eingelesen und Ergebnisse in den Ordner `output` geschrieben. 

SRF Data verwendet das [rddj-template](https://github.com/grssnbchr/rddj-template) von Timo Grossenbacher als Grundlage für seine R-Scripts.  Entstehen bei der Ausführung dieses Scripts Probleme, kann es helfen, die Anleitung von [rddj-template](https://github.com/grssnbchr/rddj-template) zu studieren. 

Debug-Informationen: *This report was generated on `r Sys.time()`. R version: `r paste0(version$major, ".", version$minor)` on `r version$platform`. For this report, CRAN packages as of `r package_date` were used.*

### GitHub

Der Code für die vorliegende Datenprozessierung ist auf [https://github.com/srfdata/`r project_name`](https://github.com/srfdata/`r project_name`) zur freien Verwendung verfügbar. 


### Lizenz

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons Lizenzvertrag" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br /><span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Dataset" property="dct:title" rel="dct:type">`r project_name`</span> von <a xmlns:cc="http://creativecommons.org/ns#" href="https://github.com/srfdata/`r project_name`" property="cc:attributionName" rel="cc:attributionURL">SRF Data</a> ist lizenziert unter einer <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Namensnennung - Weitergabe unter gleichen Bedingungen 4.0 International Lizenz</a>.

### Weitere Projekte

Code & Daten von [SRF Data](https://srf.ch/data) sind unter [https://srfdata.github.io](https://srfdata.github.io) verfügbar.

### Haftungsausschluss

Die veröffentlichten Informationen sind sorgfältig zusammengestellt, erheben aber keinen Anspruch auf Aktualität, Vollständigkeit oder Richtigkeit. Es wird keine Haftung übernommen für Schäden, die  durch die Verwendung dieses Scripts oder der daraus gezogenen Informationen entstehen. Dies gilt ebenfalls für Inhalte Dritter, die über dieses Angebot zugänglich sind.


### Originalquelle

Die Originalquelle ist die [Facebook Ad Library API](https://www.facebook.com/ads/library/api/?source=archive-landing-page). Um nachzuvollziehen, wie diese täglich angefragt wird, siehe das Script im Ordner `analysis/scripts/api_bot.R`.

### Vorgehensweise

* Täglich um Mitternacht wird die Facebook Ad Library mit dem Script in `analysis/scripts/api_bot.R` gemäss hunderten von Suchbegriffen durchsucht ("Crawl-Vorgang"). 
* Die Suchbegriffe sind in `analysis/input/pages.csv` aufgeführt und umfassen die Page-IDs aller bisherigen ParlamentarierInnen (soweit bekannt) sowie die Page-IDs der nationalen und kantonalen Partei-Sektionen. 
* Zusätzlich werden noch weitere Freitext-Suchbegriffe von Parteinamen verwendet, um möglichst viele weitere Ergebnisse zu erhalten (siehe `analysis/scripts/api_bot.R` ca. ab Zeile 55).
* Nach dem Crawl-Vorgang werden die API-Antworten im vorliegenden Script eingelesen, vorprozessiert (im Script `analysis/scripts/preprocess.R` und ausgewertet. Dabei werden verschiedene Grafiken erstellt und die aufbereiteten Daten in ein CSV gegossen (siehe Datenbeschreibung).
* Für die Auswertungen werden aus Gründen der Vergleichbarkeit jeweils nur die Daten der kantonalen und nationalen Partei-Sektionen (=API-Resultate, die auf Anfrage einer Page-ID retourniert wurden) verwendet. Zum Teil werden auch nur Daten der nationalen Sekretariate verwendet, dies ist jeweils angegeben.

### `output/ads.csv` Datenbeschreibung

| Attribut | Typ | Beschreibung |
|-------|------|-----------------------------------------------------------------------------|
| page_name:spend.upper_bound* | mixed | Angaben, die direkt von der API übernommen werden ([Datenbeschreibung](https://www.facebook.com/ads/library/api/?source=archive-landing-page)) |
| search_expression | character  | Der initiale Suchausdruck, für den die API die Ad zurückgegeben hat (i.d.R. eine Page-ID) |
| kanton | character |  Kanton der Sektion / des/der KandidatIn, falls bekannt und zutreffend |
| region | character |  Sprachregion, falls bekannt und zutreffend (hilfreich bei nationalen Pages) |
| partei | character |  Kanonischer Parteiname, falls bekannt und zutreffend |
| account_art | character |  Art der Page: "Kantonale Sektion", "Nationale Partei", "Person" (bisherige ParlamentarierInnen) oder NA (für Resultate, die durch Freitext-Suchbegriffe erhalten wurden) |
| ad_uuid | integer |  Eindeutige ID der Ad in diesem Datensatz (Achtung: Kann sich von Tag zu Tag ändern) |
| crawl_timestamp* | character |  Zeitpunkt des Crawl-Vorgangs |

*Alle Zeitangaben sind in UTC+2 (zentraleuropäische Sommerzeit CEST).

*Inhaltlich* zeigt der Datensatz alle Zeitstände (`crawl_timestamp`) einer Ad (`ad_uuid`), bei denen die von der API gelieferten Daten *zuletzt* konsistent waren. In anderen Worten: Werden von der API andere Daten geliefert (zum Beispiel neue Angaben zu Preis und Impressions, da sich diese über die Zeit ändern können), erhält der Datensatz einen neuen Eintrag mit einem neuen `crawl_timestamp` aber der gleichen `ad_uuid`, da es sich um die gleiche Ad mit aktualisierten Informationen handelt. So lassen sich Änderungen über die Zeit nachvollziehen.


## Vorbereitungen

```{r, echo=FALSE}
detach_all_packages <- function() {
  basic_packages_blank <-  c("stats",
                             "graphics",
                             "grDevices",
                             "utils",
                             "datasets",
                             "methods",
                             "base")
  basic_packages <- paste("package:", basic_packages_blank, sep = "")

  package_list <- search()[
    ifelse(unlist(gregexpr("package:", search())) == 1, TRUE, FALSE)]

  package_list <- setdiff(package_list, basic_packages)

  if (length(package_list) > 0)  for (package in package_list) {
    detach(package, character.only = TRUE, unload = TRUE)
    print(paste("package ", package, " detached", sep = ""))
  }
}

detach_all_packages()

# this allows multiple persons to use the same RMarkdown
# without adjusting the working directory by themselves all the time
source("scripts/csf.R")
path_to_wd <- csf() # if this - for some reason - does not work,
# replace with a hardcoded path, like so: "~/projects/rddj-template/analysis/"
if ( is.null(path_to_wd) | !dir.exists(path_to_wd)) {
  print("WARNING: No working directory specified for current user")
} else {
  setwd(path_to_wd)
}

# suppress scientific notation
options(scipen = 999)

# unload global rstudioapi and knitr again to avoid conflicts with checkpoint
# this is only necessary if executed within RStudio
# outside of RStudio, namely in the knit.sh script, this causes RMarkdown
# rendering to fail, thus should not be executed there
if (Sys.getenv("RSTUDIO") == "1"){
  detach_all_packages()
}
```


### Packages definieren

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# from https://mran.revolutionanalytics.com/web/packages/checkpoint/vignettes/using-checkpoint-with-knitr.html
# if you don't need a package, remove it from here (commenting is probably not sufficient)
# tidyverse: see https://blog.rstudio.org/2016/09/15/tidyverse-1-0-0/
cat("
library(rstudioapi)
library(tidyverse) # ggplot2, dplyr, tidyr, readr, purrr, tibble
library(magrittr) # pipes
library(lubridate) # dates
library(scales) # scales for ggplot2
library(jsonlite) # json
library(lintr) # code linting
library(rmarkdown)",
file = "manifest.R")
```

### Packages installieren

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# if checkpoint is not yet installed, install it (for people using this
# system for the first time)
if (!require(checkpoint)) {
  if (!require(devtools)) {
    install.packages("devtools", repos = "http://cran.us.r-project.org")
    require(devtools)
  }
  devtools::install_github("RevolutionAnalytics/checkpoint",
                           ref = "v0.3.2", # could be adapted later,
                           # as of now (beginning of July 2017
                           # this is the current release on CRAN)
                           repos = "http://cran.us.r-project.org")
  require(checkpoint)
}
# nolint start
if (!dir.exists("~/.checkpoint")) {
  dir.create("~/.checkpoint")
}
# nolint end
# install packages for the specified CRAN snapshot date
checkpoint(snapshotDate = package_date,
           project = path_to_wd,
           verbose = T,
           scanForPackages = F,
           use.knitr = F,
           R.version = R_version)
rm(package_date)
```


### Packages laden

```{r, echo=TRUE, message=FALSE, warning=FALSE}
source("manifest.R")
unlink("manifest.R")
sessionInfo()
```

### Theme definieren

```{r define theme, echo=TRUE, message=FALSE, warning=FALSE}
# some constants
default_font_color <- "#4e4d47"
default_background_color <- "#f5f5f2"
default_font_family <- "SRG SSR Type Text"

theme_srf <- function(...) {
  theme_minimal() +
  theme(
    text = element_text(family = default_font_family,
                        color = default_font_color),
    # add a subtle grid
    panel.grid.major = element_line(color = "#dbdbd9", size = 0.2),
    panel.grid.minor = element_blank(),
    # background colors
    plot.background = element_rect(fill = default_background_color,
                                   color = NA),
    panel.background = element_rect(fill = default_background_color,
                                    color = NA),
    legend.background = element_rect(fill = default_background_color,
                                     color = NA),
    # borders and margins
    plot.margin = unit(c(.5, .5, .2, .5), "cm"),
    panel.border = element_blank(),
    # panel.spacing = unit(c(-.1, 0.2, .2, 0.2), "cm"),
    # titles
    legend.title = element_text(size = 11),
    legend.text = element_text(size = 9, hjust = 0,
                               color = default_font_color),
    plot.title = element_text(size = 15, hjust = 0.5,
                              color = default_font_color),
    plot.subtitle = element_text(size = 10, hjust = 0.5,
                                 color = default_font_color,
                                 margin = margin(b = -0.1,
                                                 t = -0.1,
                                                 l = 2,
                                                 unit = "cm"),
                                 debug = F),
    # captions
    plot.caption = element_text(size = 7,
                                hjust = .5,
                                margin = margin(t = 0.2,
                                                b = 0,
                                                unit = "cm"),
                                color = "#939184"),
    ...
  )
}
```


## Daten einlesen

In `scripts/preprocess.R` werden die Daten zuerst korrekt typisiert.

Dann werden sie so dedupliziert, dass jeweils nur die letzt gecrawlte Version einer Ausprägung einer Ad bestehen bleibt. Wenn sich also während mehreren Crawl-Vorgängen an einer Ausprägung einer Ad (Ausprägung: Z.B. momentane Anzahl Impressions) nichts ändert, wird nur der jüngste Crawl-Vorgang beibehalten.

Danach werden die eindeutigen Ads extrahiert (mehrere "Versionen" einer Ad, wie sie im Ad Library Frontend vorkommen, werden als einzelne Ads gezählt).


```{r read preprocessed data, echo=TRUE, message=FALSE, warning=FALSE}
load("input/ignore/tmp/ads.RData")
load("input/ignore/tmp/reg_dist.RData")
load("input/ignore/tmp/dem_dist.RData")
```


## Auswertungen


### Plotting-Funktionen

```{r plotting functions, echo=TRUE, message=FALSE, warning=FALSE}
# party colors
big_8_colors <- c(
  "SVP" = "#4B8A3E",
  "SP" = "#F0554D",
  "Grüne" = "#84B547",
  "Grünliberal" = "#C4C43D",
  "FDP" = "#3872B5",
  "EV" = "#DEAA28",
  "CVP" = "#D6862B",
  "BDP" = "#E6C820",
  "Total" = "#4E4D47"
)

plot_total <- function(data, grouping_var, measurement_var) {
  data %>% 
    filter(!is.na(!!sym(grouping_var))) %>%
    group_by(Partei, !!sym(grouping_var)) %>% 
    summarise(summarized_var = sum(!!sym(measurement_var))) %>% 
    ggplot(aes(x = !!sym(grouping_var), y = summarized_var, fill = Partei)) +
    geom_bar(stat = "identity") +
    facet_grid(~ Partei) +
    scale_fill_manual(values = big_8_colors) +
    theme_srf() +
    labs(color = "", caption = "CC-BY-SA SRF Data 2019")
}

plot_share <- function(data, grouping_var, measurement_var) {
  data %>% 
    filter(!is.na(!!sym(grouping_var))) %>%
    group_by(Partei, !!sym(grouping_var)) %>% 
    summarise(summarized_var = sum(!!sym(measurement_var))) %>% 
    mutate(share = summarized_var / sum(summarized_var)) %>%
    ggplot(aes(x = !!sym(grouping_var), y = share, fill = Partei)) +
    geom_bar(stat = "identity") +
    geom_text(aes(y = share, label = scales::percent(round(share, 3))), 
            position = position_dodge(width = 0.5), 
            vjust = 0.5, color = "black", size = 3) +
    scale_y_continuous(labels = scales::percent) +
    facet_grid(~ Partei) +
    scale_fill_manual(values = big_8_colors) +
    theme_srf() +
    labs(color = "", caption = "CC-BY-SA SRF Data 2019")
}
```

Für die nachfolgenden Auswertungen werden jeweils nur die Daten von nationalen und kantonalen Partei-Sektionen verwendet. Zusätzliche Daten, die durch Suchbegriffe und Page-IDs bisherhiger ParlamentarierInnen anfallen, werden nicht miteinbezogen. 

### Zusammenfassende Auswertungen (jeweils nur letzter Stand)

```{r prepare data for analysis, echo=TRUE, message=FALSE, warning=FALSE}
ads_to_analyze <- ads %>% 
  # only keep cantonal and national sections, not candidates
  filter(!is.na(`Account-Art`)) %>% 
  filter(`Account-Art` != "Person") %>% 
  group_by(ad_uuid) %>% 
  arrange(desc(scrape_date)) %>% 
  slice(1) %>% 
  ungroup()
```

#### Gesamtanzahl Ads nach Page / Partei / Total

```{r number of ads per page/party, echo=TRUE, message=FALSE, warning=FALSE}
ads_to_analyze %>% 
  count(page_name) %>% 
  arrange(desc(n)) %>% 
  knitr::kable()

ads_to_analyze %>% 
  count(Partei) %>% 
  arrange(desc(n)) %>% 
  knitr::kable()

ads_to_analyze %>% 
  count() %>% 
  knitr::kable()
```

#### Minimal- und Maximalausgaben nach Page / Partei

Alle Angaben in CHF.

```{r minimally and maximally spent per page, echo=TRUE, message=FALSE, warning=FALSE}
ads_to_analyze %>% 
  group_by(page_name) %>% 
  summarize(min_spent = sum(spend.lower_bound, na.rm = TRUE),
            max_spent = sum(spend.upper_bound, na.rm = TRUE)) %>% 
  arrange(desc(max_spent)) %>% 
  knitr::kable()
```

Total nach Partei (inkl. Kantonalsektionen)

```{r minimally and maximally spent per party, echo=TRUE, message=FALSE, warning=FALSE}
ads_to_analyze %>% 
  group_by(Partei) %>% 
  summarize(min_spent = sum(spend.lower_bound, na.rm = TRUE),
            max_spent = sum(spend.upper_bound, na.rm = TRUE)) %>% 
  arrange(desc(max_spent)) %>% 
  knitr::kable()
```

Total nach Partei (ohne Kantonalsektionen)

```{r minimally and maximally spent per party without cantonal sections, echo=TRUE, message=FALSE, warning=FALSE}
ads_to_analyze %>% 
  filter(`Account-Art` == "Nationale Partei") %>% 
  group_by(Partei) %>% 
  summarize(min_spent = sum(spend.lower_bound, na.rm = TRUE),
            max_spent = sum(spend.upper_bound, na.rm = TRUE)) %>% 
  arrange(desc(max_spent)) %>% 
  knitr::kable()
```

##### Gesamt

Mit kantonalen Sektionen

```{r minimally and maximally spent total, echo=TRUE, message=FALSE, warning=FALSE}
# Gesamtausgaben
ads_to_analyze %>% 
  summarize(min_spent = sum(spend.lower_bound, na.rm = TRUE),
            max_spent = sum(spend.upper_bound, na.rm = TRUE)) %>% 
  arrange(desc(max_spent)) %>% 
  knitr::kable()
```

##### Visualisierung

Ohne kantonale Sektionen.

```{r visualization minimally and maximally spent per party, echo=TRUE, message=FALSE, warning=FALSE}

ads_to_analyze %>% 
  group_by(Partei) %>% 
  filter(`Account-Art` == "Nationale Partei") %>% 
  summarize(min_spent = sum(spend.lower_bound, na.rm = TRUE),
            max_spent = sum(spend.upper_bound, na.rm = TRUE)) %>%
  arrange(desc(min_spent)) %>% 
  mutate(Partei = fct_reorder(Partei, min_spent, last)) %>% 
  ggplot() +
  geom_segment(aes(x = min_spent, y = Partei,
  xend = max_spent, yend = Partei), size = 1) +
  geom_point(aes(x = min_spent, y = Partei, color = "Mindestens"), 
             size = 2, shape = 15) +
  geom_point(aes(x = max_spent, y = Partei, color = "Höchstens"), 
             size = 2, shape = 15) +
  labs(x = "Ausgaben [CHF]", y = "Partei", color = "", 
       title = "FB Ad Library: Ausgaben nach Partei",
       subtitle = "Ohne kantonale Sektionen",
       caption = "CC-BY-SA SRF Data 2019") +
  theme_srf() +
  scale_x_continuous(labels = function(x) 
    format(x, big.mark = "'", scientific = FALSE))
  
```


#### Minimal- und Maximal-Impressions nach Page / Partei

Parteien zuerst mit, dann ohne kantonale Sektionen.

```{r minimal and maximal impressions per page/party, echo=TRUE, message=FALSE, warning=FALSE}
ads_to_analyze %>% 
  group_by(page_name) %>% 
  summarize(min_impressions = sum(impressions.lower_bound, na.rm = TRUE),
            max_impressions = sum(impressions.upper_bound, na.rm = TRUE)) %>% 
  arrange(desc(min_impressions)) %>% 
  knitr::kable()


ads_to_analyze %>% 
  group_by(Partei) %>% 
  summarize(min_impressions = sum(impressions.lower_bound, na.rm = TRUE),
            max_impressions = sum(impressions.upper_bound, na.rm = TRUE)) %>% 
  arrange(desc(min_impressions)) %>% 
  knitr::kable()

ads_to_analyze %>% 
  filter(`Account-Art` == "Nationale Partei") %>% 
  group_by(Partei) %>% 
  summarize(min_impressions = sum(impressions.lower_bound, na.rm = TRUE),
            max_impressions = sum(impressions.upper_bound, na.rm = TRUE)) %>% 
  arrange(desc(min_impressions)) %>% 
  knitr::kable()

```


##### Visualisierung

Ohne kantonale Sektionen.

```{r visualization minimal and maximal impressions per party, echo=TRUE, message=FALSE, warning=FALSE}
ads_to_analyze %>% 
  filter(`Account-Art` == "Nationale Partei") %>% 
  group_by(Partei) %>% 
  summarize(min_impressions = sum(impressions.lower_bound, na.rm = TRUE),
            max_impressions = sum(impressions.upper_bound, na.rm = TRUE)) %>% 
  arrange(desc(max_impressions)) %>% 
  mutate(Partei = 
           fct_reorder(Partei, min_impressions, last)) %>% 
  ggplot() +
  geom_segment(aes(x = min_impressions, y = Partei,
  xend = max_impressions, yend = Partei), size = 1) +
  geom_point(aes(x = min_impressions, y = Partei, 
                 color = "Mindestens"), 
             size = 2, shape = 15) +
  geom_point(aes(x = max_impressions, y = Partei, 
                 color = "Höchstens"), 
             size = 2, shape = 15) +
  labs(x = "Impressions", y = "Partei", color = "", 
       title = "FB Ad Library: Impressions nach Partei",
       subtitle = "Ohne kantonale Sektionen",
       caption = "CC-BY-SA SRF Data 2019") +
  theme_srf() +
  scale_x_continuous(labels = function(x) 
    format(x, big.mark = "'", scientific = FALSE))

```

##### Gesamt

Mit kantonalen Sektionen

```{r total minimal and maximal expressions with cantonal sections, echo=TRUE, message=FALSE, warning=FALSE}
ads_to_analyze %>% 
  summarize(min_impressions = sum(impressions.lower_bound, na.rm = TRUE),
            max_impressions = sum(impressions.upper_bound, na.rm = TRUE)) %>% 
  arrange(desc(max_impressions)) %>% 
  knitr::kable()
```



### Auswertungen über die Zeit

#### Anzahl Ads gestartet, pro Woche

```{r new ads per week, echo=TRUE, message=FALSE, warning=FALSE}
ads_to_analyze %>% 
  # Neue Variable: week_number
  mutate(week_number = isoweek(ad_delivery_start_time)) %>% 
  group_by(week_number, Partei) %>% 
  # Neue Ads pro Woche: week_ads
  summarise(week_ads = sum(n())) %>% 
  ggplot(aes(x = week_number, y = week_ads, fill = Partei)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = big_8_colors) +
  labs(x = "Kalenderwoche", y = "Anzahl neue Ads", color = "", 
       title = "FB Ad Library: Anzahl gestartete Ads pro Woche",
       caption = "CC-BY-SA SRF Data 2019") +
  theme_srf()

```

### Auswertungen der demographischen Zielgruppen

Jeweils nationale und kantonale Sektionen zusammengenommen.

```{r prepare data for analysis demographic, echo=TRUE, message=FALSE, warning=FALSE}
# only latest version of every ad -> uuids of ads_to_analyze
dem_dist_ads <- ads_to_analyze %>% 
  left_join(dem_dist, by = "uuid")

# views: How many people (age/gender) saw the ad
dem_dist_ads %<>% 
  mutate(views.lower_bound = impressions.lower_bound * percentage,
         views.upper_bound = impressions.upper_bound * percentage,
         costs.lower_bound = spend.lower_bound * percentage,
         costs.upper_bound = spend.upper_bound * percentage
         )
```

#### Geschlecht

```{r visualization impressions on gender, echo=TRUE, message=FALSE, warning=FALSE}
plot_total(dem_dist_ads, "gender", "costs.lower_bound") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = "Geschlecht", y = "Mindest-Ausgaben in CHF", 
       title = "FB Ad Library: Ausgaben nach Geschlecht",
       subtitle = "Gerechnet wird mit den Mindest-Ausgaben") 
  


# total impressions by gender
plot_total(dem_dist_ads, "gender", "views.lower_bound") +  
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = "Geschlecht", y = "Mindest-Impressions", 
       title = "FB Ad Library: Impressions nach Geschlecht",
       subtitle = "Gerechnet wird mit den Mindest-Impressions")


  
# Share of costs by gender
plot_share(dem_dist_ads, "gender", "costs.lower_bound") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = "Geschlecht", y = "Anteil der Mindest-Ausgaben", 
       title = "FB Ad Library: Anteil der Ausgaben nach Geschlecht",
       subtitle = "Gerechnet wird mit den Mindest-Ausgaben")
  
    
# Share of impressions by gender
plot_share(dem_dist_ads, "gender", "views.lower_bound") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = "Geschlecht", y = "Anteil der Mindest-Impressions", 
       title = "FB Ad Library: Anteil Impressions nach Geschlecht",
       subtitle = "Gerechnet wird mit den Mindest-Impressions")
 
```

#### Alter

```{r visualization impressions on age group, echo=TRUE, message=FALSE, warning=FALSE}
# omit age group 13-17 (FDP)
dem_dist_ads %<>%
  filter(!age == "13-17")


# total costs per age group
plot_total(dem_dist_ads, "age", "costs.lower_bound") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = "Altersgruppe", y = "Mindest-Ausgaben in CHF", 
       title = "FB Ad Library: Ausgaben nach Altersgruppe",
       subtitle = "Gerechnet wird mit den Mindest-Ausgaben") 


# total impressions per age group
plot_total(dem_dist_ads, "age", "views.lower_bound") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = "Altersgruppe", y = "Mindest-Impressions", 
       title = "FB Ad Library: Impressions nach Altersgruppe",
       subtitle = "Gerechnet wird mit den Mindest-Impressions")  


# share of costs by age group
plot_share(dem_dist_ads, "age", "costs.lower_bound") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = "Altersgruppe", y = "Anteil der Mindest-Ausgaben", 
       title = "FB Ad Library: Anteil der Ausgaben nach Altersgruppe",
       subtitle = "Gerechnet wird mit den Mindest-Ausgaben")


# share of impressions by age group
plot_share(dem_dist_ads, "age", "views.lower_bound") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = "Altersgruppe", y = "Anteil der Mindest-Impressions", 
       title = "FB Ad Library: Anteil Impressions nach Altersgruppe",
       subtitle = "Gerechnet wird mit den Mindest-Impressions")


```

### Auswertungen der regionalen Zielgruppen (nach Kantonen)

Hierfür werden nur die nationalen Sektionen verwendet, da nicht alle kantonalen Sektionen mitmachen und es somit zu Verzerrungen kommen würde.

```{r prepare data for analysis regional, echo=TRUE, message=FALSE, warning=FALSE}
# Rename Cantons, consistent names
canton_names <- c(
  "^Basel-City$" = "Basel-Stadt",
  "^Canton of Geneva$" = "Genf",
  "^Canton of Glarus$" = "Glarus",
  "^Canton of Nidwalden$" = "Nidwalden",
  "^Canton of Obwalden$" = "Obwalden",
  "^Canton of St. Gallen$" = "St. Gallen",
  "^Fribourg$" = "Freiburg",
  "^Neuchâtel$" = "Neuenburg",
  "^Ticino$" = "Tessin",
  "^Valais$" = "Wallis",
  "^Vaud$" = "Waadt",
  "^Unknown$" = NA_character_
)

reg_dist %<>%
  mutate(region = str_replace_all(region, canton_names)) %>% 
  mutate(percentage = as.numeric(percentage))
  

# join the dfs
reg_dist_ads <- ads_to_analyze %>% 
  left_join(reg_dist, by = "uuid") %>% 
  # only retain national party sections
  filter(`Account-Art` == "Nationale Partei")

# views = How many people (canton) saw the ad
reg_dist_ads %<>% 
  mutate(views.lower_bound = impressions.lower_bound * percentage,
         views.upper_bound = impressions.upper_bound * percentage,
         costs.lower_bound = spend.lower_bound * percentage,
         costs.upper_bound = spend.upper_bound * percentage
         )

```


```{r visualization impressions on canton, echo=TRUE, message=FALSE, warning=FALSE}
# total costs by canton
plot_total(reg_dist_ads, "region", "costs.lower_bound") +
  coord_flip() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = "Kanton", y = "Mindest-Ausgaben", 
       title = "FB Ad Library: Ausgaben nach Kanton", 
       subtitle = "Gerechnet wird mit den Mindest-Ausgaben")


# total impressions by canton
plot_total(reg_dist_ads, "region", "views.lower_bound") +
  coord_flip() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = "Kanton", y = "Mindest-Impressions", 
       title = "FB Ad Library: Impressions nach Kanton",
       subtitle = "Gerechnet wird mit den Mindest-Impressions")



# Share of costs by canton
plot_share(reg_dist_ads, "region", "costs.lower_bound") +
  coord_flip() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = "Kanton", y = "Anteil der Mindest-Ausgaben", 
       title = "FB Ad Library: Anteil Ausgaben nach Kanton", 
       subtitle = "Gerechnet wird mit den Mindest-Ausgaben")


# Share of impressions by canton
plot_share(reg_dist_ads, "region", "views.lower_bound") +
  coord_flip() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = "Kanton", y = "Anteil der Mindest-Impressions", 
       title = "FB Ad Library: Anteil Impressions nach Kanton",
       subtitle = "Gerechnet wird mit den Mindest-Impressions")

  

# normalize with count of NR-Sitze
canton_names2 <- c(
  "^Bern / Berne$" = "Bern",
  "^Fribourg / Freiburg$" = "Freiburg",
  "^Graubünden / Grigioni / Grischun$" = "Graubünden",
  "^Ticino$" = "Tessin",
  "^Vaud$" = "Waadt",
  "^Valais / Wallis$" = "Wallis",
  "^Neuchâtel$" = "Neuenburg",
  "^Genève$" = "Genf"
)
# data source: BFS, 2015
canton_voters <- 
  read_delim("input/eligible_voters_cantons.csv", delim = ";") %>% 
  rename(region = kanton_bezeichnung) %>% 
  filter(region != "Schweiz") %>% 
  mutate(region = str_replace_all(region, canton_names2)) %>% 
  select(region, wahlberechtigte)

reg_dist_ads_normalized <- reg_dist_ads %>%
  group_by(Partei, region) %>% 
  summarise(Ausgaben = sum(costs.lower_bound)) %>% 
  left_join(canton_voters, by = "region") %>% 
  ungroup()

# share of cantons, normalized by seats
reg_dist_ads_normalized %<>% 
  filter(!is.na(region)) %>%
  mutate(costs_per_1000_voters_in_chf = 
           round( (Ausgaben / wahlberechtigte) * 1000, 1)) %>% 
  select(Partei, region, costs_per_1000_voters_in_chf) %>% 
  group_by(Partei) %>% 
  arrange(desc(costs_per_1000_voters_in_chf))

plot_total(reg_dist_ads_normalized,
           "region", 
           "costs_per_1000_voters_in_chf") +
  coord_flip() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = "Kanton", y = "Mindest-Ausgaben pro tausend Wahlberechtigte in CHF", 
       title = "FB Ad Library: Ausgaben pro tausend Wahlberechtigte",
       subtitle = "Gerechnet wird mit den Mindest-Ausgaben")

reg_dist_total <- reg_dist_ads_normalized %>% 
  group_by(region) %>% 
  summarize(total = sum(costs_per_1000_voters_in_chf)) %>% 
  mutate(Partei = as.factor("Total")) %>% 
  mutate(region = as.factor(region)) %>% 
  mutate(region = fct_reorder(region, total))

reg_dist_total %>% 
  plot_total("region", "total") +
  coord_flip() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = "Kanton", y = "Mindest-Ausgaben pro tausend Wahlberechtigte in CHF", 
       title = "FB Ad Library: Ausgaben pro tausend Wahlberechtigte",
       subtitle = "Gerechnet wird mit den Mindest-Ausgaben")

rm(canton_voters)
```

## Daten-Export

Datenbeschreibung siehe oben.

```{r}
ads %>% 
  select(-uuid) %>% 
  select(page_name:ad_creative_link_description, 
         impressions.lower_bound:spend.upper_bound, search_expression,
         Kanton:`Account-Art`, ad_uuid, crawl_timestamp = scrape_date) %>%
  rename(kanton = Kanton, region = Region, 
         partei = Partei, account_art = `Account-Art`) %>% 
  arrange(ad_uuid) %>% 
  write_csv(path = "output/ads.csv")
```

## Linting

Der Code in diesem RMarkdown wird mit [lintr](https://github.com/jimhester/lintr) automatisch auf den Wickham'schen [tidyverse style guide](http://style.tidyverse.org/) überprüft.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
lintr::lint("main.Rmd", linters =
              lintr::with_defaults(
                commented_code_linter = NULL,
                trailing_whitespace_linter = NULL
                )
            )
# if you have additional scripts and want them to be linted too, add them here
# lintr::lint("scripts/my_script.R")
```
